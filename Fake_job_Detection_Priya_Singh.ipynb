{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb087dcd-011b-4b2e-aede-4c8d38076fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data:\n",
      "   job_id                                      title            location  \\\n",
      "0       1                           Marketing Intern    US, NY, New York   \n",
      "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
      "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
      "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
      "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
      "\n",
      "  department salary_range                                    company_profile  \\\n",
      "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
      "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
      "2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
      "3      Sales          NaN  Our passion for improving quality of life thro...   \n",
      "4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n",
      "\n",
      "                                         description  \\\n",
      "0  Food52, a fast-growing, James Beard Award-winn...   \n",
      "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
      "2  Our client, located in Houston, is actively se...   \n",
      "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
      "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
      "\n",
      "                                        requirements  \\\n",
      "0  Experience with content management systems a m...   \n",
      "1  What we expect from you:Your key responsibilit...   \n",
      "2  Implement pre-commissioning and commissioning ...   \n",
      "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
      "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
      "\n",
      "                                            benefits  telecommuting  \\\n",
      "0                                                NaN              0   \n",
      "1  What you will get from usThrough being part of...              0   \n",
      "2                                                NaN              0   \n",
      "3  Our culture is anything but corporate—we have ...              0   \n",
      "4                              Full Benefits Offered              0   \n",
      "\n",
      "   has_company_logo  has_questions employment_type required_experience  \\\n",
      "0                 1              0           Other          Internship   \n",
      "1                 1              0       Full-time      Not Applicable   \n",
      "2                 1              0             NaN                 NaN   \n",
      "3                 1              0       Full-time    Mid-Senior level   \n",
      "4                 1              1       Full-time    Mid-Senior level   \n",
      "\n",
      "  required_education                   industry              function  \\\n",
      "0                NaN                        NaN             Marketing   \n",
      "1                NaN  Marketing and Advertising      Customer Service   \n",
      "2                NaN                        NaN                   NaN   \n",
      "3  Bachelor's Degree          Computer Software                 Sales   \n",
      "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
      "\n",
      "   fraudulent  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17880 entries, 0 to 17879\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_id               17880 non-null  int64 \n",
      " 1   title                17880 non-null  object\n",
      " 2   location             17534 non-null  object\n",
      " 3   department           6333 non-null   object\n",
      " 4   salary_range         2868 non-null   object\n",
      " 5   company_profile      14572 non-null  object\n",
      " 6   description          17879 non-null  object\n",
      " 7   requirements         15184 non-null  object\n",
      " 8   benefits             10668 non-null  object\n",
      " 9   telecommuting        17880 non-null  int64 \n",
      " 10  has_company_logo     17880 non-null  int64 \n",
      " 11  has_questions        17880 non-null  int64 \n",
      " 12  employment_type      14409 non-null  object\n",
      " 13  required_experience  10830 non-null  object\n",
      " 14  required_education   9775 non-null   object\n",
      " 15  industry             12977 non-null  object\n",
      " 16  function             11425 non-null  object\n",
      " 17  fraudulent           17880 non-null  int64 \n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 2.5+ MB\n",
      "None\n",
      "\n",
      "Missing Values per Column:\n",
      "job_id                     0\n",
      "title                      0\n",
      "location                 346\n",
      "department             11547\n",
      "salary_range           15012\n",
      "company_profile         3308\n",
      "description                1\n",
      "requirements            2696\n",
      "benefits                7212\n",
      "telecommuting              0\n",
      "has_company_logo           0\n",
      "has_questions              0\n",
      "employment_type         3471\n",
      "required_experience     7050\n",
      "required_education      8105\n",
      "industry                4903\n",
      "function                6455\n",
      "fraudulent                 0\n",
      "dtype: int64\n",
      "\n",
      "Target (fraudulent) Distribution:\n",
      "fraudulent\n",
      "0    17014\n",
      "1      866\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset Summary:\n",
      "              job_id                    title         location department  \\\n",
      "count   17880.000000                    17880            17534       6333   \n",
      "unique           NaN                    11231             3105       1337   \n",
      "top              NaN  English Teacher Abroad   GB, LND, London      Sales   \n",
      "freq             NaN                      311              718        551   \n",
      "mean     8940.500000                      NaN              NaN        NaN   \n",
      "std      5161.655742                      NaN              NaN        NaN   \n",
      "min         1.000000                      NaN              NaN        NaN   \n",
      "25%      4470.750000                      NaN              NaN        NaN   \n",
      "50%      8940.500000                      NaN              NaN        NaN   \n",
      "75%     13410.250000                      NaN              NaN        NaN   \n",
      "max     17880.000000                      NaN              NaN        NaN   \n",
      "\n",
      "       salary_range                                    company_profile  \\\n",
      "count          2868                                              14572   \n",
      "unique          874                                               1709   \n",
      "top             0-0  We help teachers get safe &amp; secure jobs ab...   \n",
      "freq            142                                                726   \n",
      "mean            NaN                                                NaN   \n",
      "std             NaN                                                NaN   \n",
      "min             NaN                                                NaN   \n",
      "25%             NaN                                                NaN   \n",
      "50%             NaN                                                NaN   \n",
      "75%             NaN                                                NaN   \n",
      "max             NaN                                                NaN   \n",
      "\n",
      "                                              description  \\\n",
      "count                                               17879   \n",
      "unique                                              14801   \n",
      "top     Play with kids, get paid for it Love travel? J...   \n",
      "freq                                                  379   \n",
      "mean                                                  NaN   \n",
      "std                                                   NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "\n",
      "                                             requirements  \\\n",
      "count                                               15184   \n",
      "unique                                              11965   \n",
      "top     University degree required. TEFL / TESOL / CEL...   \n",
      "freq                                                  410   \n",
      "mean                                                  NaN   \n",
      "std                                                   NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "\n",
      "                   benefits  telecommuting  has_company_logo  has_questions  \\\n",
      "count                 10668   17880.000000      17880.000000   17880.000000   \n",
      "unique                 6203            NaN               NaN            NaN   \n",
      "top     See job description            NaN               NaN            NaN   \n",
      "freq                    726            NaN               NaN            NaN   \n",
      "mean                    NaN       0.042897          0.795302       0.491723   \n",
      "std                     NaN       0.202631          0.403492       0.499945   \n",
      "min                     NaN       0.000000          0.000000       0.000000   \n",
      "25%                     NaN       0.000000          1.000000       0.000000   \n",
      "50%                     NaN       0.000000          1.000000       0.000000   \n",
      "75%                     NaN       0.000000          1.000000       1.000000   \n",
      "max                     NaN       1.000000          1.000000       1.000000   \n",
      "\n",
      "       employment_type required_experience required_education  \\\n",
      "count            14409               10830               9775   \n",
      "unique               5                   7                 13   \n",
      "top          Full-time    Mid-Senior level  Bachelor's Degree   \n",
      "freq             11620                3809               5145   \n",
      "mean               NaN                 NaN                NaN   \n",
      "std                NaN                 NaN                NaN   \n",
      "min                NaN                 NaN                NaN   \n",
      "25%                NaN                 NaN                NaN   \n",
      "50%                NaN                 NaN                NaN   \n",
      "75%                NaN                 NaN                NaN   \n",
      "max                NaN                 NaN                NaN   \n",
      "\n",
      "                                   industry                function  \\\n",
      "count                                 12977                   11425   \n",
      "unique                                  131                      37   \n",
      "top     Information Technology and Services  Information Technology   \n",
      "freq                                   1734                    1749   \n",
      "mean                                    NaN                     NaN   \n",
      "std                                     NaN                     NaN   \n",
      "min                                     NaN                     NaN   \n",
      "25%                                     NaN                     NaN   \n",
      "50%                                     NaN                     NaN   \n",
      "75%                                     NaN                     NaN   \n",
      "max                                     NaN                     NaN   \n",
      "\n",
      "          fraudulent  \n",
      "count   17880.000000  \n",
      "unique           NaN  \n",
      "top              NaN  \n",
      "freq             NaN  \n",
      "mean        0.048434  \n",
      "std         0.214688  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Day 2: Understanding and Loading the Dataset\n",
    " \n",
    "import pandas as pd\n",
    " \n",
    "# Load dataset (after downloading from Kaggle)\n",
    "\n",
    "df = pd.read_csv('Fake_Jobs_Postings.csv')\n",
    " \n",
    "# Display first few rows\n",
    "\n",
    "print(\"Sample Data:\")\n",
    "\n",
    "print(df.head())\n",
    " \n",
    "# Display basic info\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "\n",
    "print(df.info())\n",
    " \n",
    "# Check for missing values\n",
    "\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "\n",
    "print(df.isnull().sum())\n",
    " \n",
    "# Check distribution of target variable\n",
    "\n",
    "print(\"\\nTarget (fraudulent) Distribution:\")\n",
    "\n",
    "print(df['fraudulent'].value_counts())\n",
    " \n",
    "# Basic statistics\n",
    "\n",
    "print(\"\\nDataset Summary:\")\n",
    "\n",
    "print(df.describe(include='all'))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1ca232-355a-4c00-bb03-4b9d99ee36ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 17880\n"
     ]
    }
   ],
   "source": [
    "#Total number of records\n",
    "print(\"Total number of records:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e443d47-66d6-4c88-bfbd-a5aee572161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "job_id                     0\n",
      "title                      0\n",
      "location                 346\n",
      "department             11547\n",
      "salary_range           15012\n",
      "company_profile         3308\n",
      "description                1\n",
      "requirements            2696\n",
      "benefits                7212\n",
      "telecommuting              0\n",
      "has_company_logo           0\n",
      "has_questions              0\n",
      "employment_type         3471\n",
      "required_experience     7050\n",
      "required_education      8105\n",
      "industry                4903\n",
      "function                6455\n",
      "fraudulent                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Number of missing values per column\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e187966-8c81-4eea-a3c8-9a0d2da5cad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Real vs Fake Jobs:\n",
      "fraudulent\n",
      "0    17014\n",
      "1      866\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label meaning:\n",
      "0 = Real Job\n",
      "1 = Fake Job\n"
     ]
    }
   ],
   "source": [
    "#Count of real vs fake jobs\n",
    "print(\"Count of Real vs Fake Jobs:\")\n",
    "print(df[\"fraudulent\"].value_counts())\n",
    "print(\"\\nLabel meaning:\")\n",
    "print(\"0 = Real Job\")\n",
    "print(\"1 = Fake Job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46204d3e-844d-414d-a4f6-a0afb31470ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Fake Job Descriptions:\n",
      "Example 1:\n",
      "IC&amp;E Technician | Bakersfield, CA Mt. PosoPrincipal Duties and Responsibilities: Calibrates, tests, maintains, troubleshoots, and installs all power plant instrumentation, control systems and electrical equipment.Performs maintenance on motor control centers, motor operated valves, generators, excitation equipment and motors.Performs preventive, predictive and corrective maintenance on equipment, coordinating work with various team members.Designs and installs new equipment and/or system modifications.Troubleshoots and performs maintenance on DC backup power equipment, process controls, programmable logic controls (PLC), and emission monitoring equipment.Uses maintenance reporting system to record time and material use, problem identified and corrected, and further action required; provides complete history of maintenance on equipment.Schedule, coordinate, work with and monitor contractors on specific tasks, as required.Follows safe working practices at all times.Identifies safety hazards and recommends solutions.Follows environmental compliance work practices.Identifies environmental non-compliance problems and assist in implementing solutions.Assists other team members and works with all departments to support generating station in achieving their performance goals.Trains other team members in the areas of instrumentation, control, and electrical systems.Performs housekeeping assignments, as directed.Conduct equipment and system tagging according to company and plant rules and regulations.Perform equipment safety inspections, as required, and record results as appropriate. Participate in small construction projects.  Read and interpret drawings, sketches, prints, and specifications, as required.Orders parts as needed to affect maintenance and repair.Performs Operations tasks on an as-needed basis and other tasks as assigned.Available within a reasonable response time for emergency call-ins and overtime, plus provide acceptable off-hour contact by phone and company pager.          Excellent Verbal and Written Communications Skills:Ability to coordinate work activities with other team members on technical subjects across job families.Ability to work weekends, holidays, and rotating shifts, as required.\n",
      "--------------------------------------------------------------------------------\n",
      "Example 2:\n",
      "The group has raised a fund for the purchase of homes in the Southeast. The student on this project will help them build their investments from the ground up and will help with the analysis and modeling of their investments.  We should be looking for someone with a strong general finance skills and has a lot of entrepreneurial ability.\n",
      "--------------------------------------------------------------------------------\n",
      "Example 3:\n",
      "Technician Instrument &amp; ControlsLocation Deweyville, TXLocation Name: NRG Cottonwood EnergyCategory: MaintenanceState/City: US-TX-DeweyvilleType: Full Time Hourly# Openings: 1Details About this Career Opportunity:Overview:Company Profile:We deliver cleaner and smarter energy choices for our customers, backed by the nation’s largest independent power generation portfolio of fossil fuel, nuclear, solar and wind facilities. A Fortune 500 company is challenging the U.S. energy industry by becoming the largest developer of solar power, building the first privately-funded electric vehicle charging infrastructure, and providing customers with the most advanced smart energy solutions to better manage their energy use. In addition to 47,000 megawatts of generation capacity, enough to supply nearly 40 million homes, our retail electricity providers serve more than two million customers.GENERAL SUMMARYThe Instrumentation Controls and Electrical Technician (IC&amp;E) is responsible for the maintenance and repair of all instruments, control systems and electrical equipment in the power plant and the associated facilities. The IC&amp;E Technician performs work of high skill in the inspection repair, testing, adjustment, installation and removal of all electronic and electrical power plant equipment and systems.PRIMARY FUNCTIONS-Safely perform preventive and corrective maintenance on all plant equipment, systems, and emergency backup systems.-Maintain complete equipment files, logs, and drawings for all designated equipment.-Assist in maintaining and controlling spare parts inventory to maintain plant reliability. Assist in physical inventories.-Participate in the administrative maintenance of the plant operating manuals, technical references, prints and diagrams and preventive/predictive maintenance records.-Inspect repair, install and remove all types of motors, generators, transformers, switches, control equipment, wiring, electrical signal and communication systems, and storage batteries, and work with electrical systems up to and including 4160 volts.-Conduct trouble shooting and analysis on DCS, PLC and GE Mark VI turbine control equipment.-Maintain all plant instrumentation and electrical test equipment.-Fully support and participate in NAES Safety and Regulatory Compliance Programs.-Complete other tasks as assigned by the Maintenance Manager or the Plant Manager.SCOPE OF RESPONSIBILITYThe IC&amp;E Technician operates from established and well-known procedures under minimum supervision, performing duties independently with only general direction given. Decisions are made within prescribed operating and casualty procedures and guidelines. The ICE Technician encounters recurring work situations of high complexity, with occasional variations from the norm.The IC&amp;E Technician must perform work in a safe manner resulting in no accidents, in compliance with all environmental permits at all times. The ICE Technician must effectively communicate information to supervision and fellow plant personnel, relative to the condition of the plant equipment and performance, and provide suggestions for plant improvements. The ICE Technician must perform duties in such a way to result in an optimum cost-benefit ratio.The IC&amp;E Technician may also be assigned the additional responsibility of Maintenance Coordinator/Planner for the site. This is a collateral assignment given to a selected maintenance department technician to assist the Operations and Maintenance Manager with the routine planning and coordination of the site equipment maintenance.The duties include:-The planning and review of the preventative, predictive and pro-active type maintenance.-A more in-depth knowledge and ability to use the CMMS system to provide the necessary review and planning to support the O&amp;M Manager in weekly work routines.-Ability to provide the cognitive coordinated efforts necessary to ensure that weekly routines and preventative maintenance are scheduled and documented as complete when the respective maintenance technician indicates that the work has been performed.-Provide the coordination efforts necessary in support of allowing the O&amp;M Manager to provide the necessary supervision and direction of the maintenance technicians.All employees have the responsibility to both the customer and their co-workers to do the job right the first time and to ensure the customers' needs are being met.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Display 3 examples of fake job descriptions\n",
    "print(\"Examples of Fake Job Descriptions:\")\n",
    "fake_jobs = df[df[\"fraudulent\"] == 1][\"description\"].head(3)\n",
    "\n",
    "# Print 3 sample fake descriptions\n",
    "for i, desc in enumerate(fake_jobs, 1):\n",
    "    print(f\"Example {i}:\\n{desc}\\n{'-'*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54867c2a-679d-4c34-9246-b0793a71a8cc",
   "metadata": {},
   "source": [
    "Which feature has the most missing values?\n",
    "The column with the most missing values is salary_range\n",
    "\n",
    "Why job descriptions are more useful than job titles for fake detection?\n",
    "Job descriptions contain detailed content, including responsibilities, requirements, and scam indicators, whereas titles are short and generic. Therefore, descriptions provide richer information for detecting fake job postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce7c122-3957-44bb-89ab-cb12922a35ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " Organised - Focused - Vibrant - Awesome!Do you have a passion for customer service? Slick typing skills? Maybe Account Management? ...And think administration is cooler than a polar bear on a jetski? Then we need to hear you! We are the Cloud Video Production Service and opperating on a glodal level\n",
      "\n",
      "Cleaned Text:\n",
      " organised focused vibrant awesome passion customer service slick typing skill maybe account management think administration cooler polar bear jetski need hear cloud video production service opperating glodal level yeah pretty cool serious delivering world class product excellent customer service rap\n",
      "\n",
      "Example of Cleaned Data:\n",
      "                                         description  \\\n",
      "0  Food52, a fast-growing, James Beard Award-winn...   \n",
      "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
      "2  Our client, located in Houston, is actively se...   \n",
      "\n",
      "                                   clean_description  \n",
      "0  food fast growing james beard award winning on...  \n",
      "1  organised focused vibrant awesome passion cust...  \n",
      "2  client located houston actively seeking experi...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Task 1:\\n\\nWrite your own cleaning function that:\\nRemoves HTML, numbers, and punctuation\\nConverts text to lowercase\\nRemoves stopwords\\nReturns a cleaned version of the company_profile column\\nTask 2:\\nCount the average number of words before and after cleaning for job descriptions.\\nDiscuss: Did the cleaning remove too much or just enough?\\n '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Day 3: Text Cleaning and Preprocessing\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "# Download resources (run once)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('wordnet')\n",
    " \n",
    "# Load dataset (same as Day 2)\n",
    "\n",
    "df = pd.read_csv('Fake_Jobs_Postings.csv')\n",
    " \n",
    "# Define text cleaning function\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    if pd.isnull(text):\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Lowercase\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove HTML tags\n",
    "\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "\n",
    "    # 3. Remove URLs\n",
    "\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "\n",
    "    # 4. Remove punctuation and numbers\n",
    "\n",
    "    text = re.sub(r'[%s\\d]' % re.escape(string.punctuation), ' ', text)\n",
    "\n",
    "    # 5. Remove extra spaces\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # 6. Remove stopwords and lemmatize\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]\n",
    "\n",
    "    return \" \".join(words)\n",
    " \n",
    "# Apply cleaning to key text columns\n",
    "\n",
    "df['clean_description'] = df['description'].apply(clean_text)\n",
    " \n",
    "# Show before and after\n",
    "\n",
    "print(\"Original Text:\\n\", df['description'].iloc[1][:300])\n",
    "\n",
    "print(\"\\nCleaned Text:\\n\", df['clean_description'].iloc[1][:300])\n",
    " \n",
    "# Check for any remaining issues\n",
    "\n",
    "print(\"\\nExample of Cleaned Data:\")\n",
    "\n",
    "print(df[['description', 'clean_description']].head(3))\n",
    "\n",
    " \n",
    "'''Task 1:\n",
    "\n",
    "Write your own cleaning function that:\n",
    "Removes HTML, numbers, and punctuation\n",
    "Converts text to lowercase\n",
    "Removes stopwords\n",
    "Returns a cleaned version of the company_profile column\n",
    "Task 2:\n",
    "Count the average number of words before and after cleaning for job descriptions.\n",
    "Discuss: Did the cleaning remove too much or just enough?\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f77a779-3480-443b-a063-acea533e4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Company Profile:\n",
      " 90 Seconds, the worlds Cloud Video Production Service.90 Seconds is the worlds Cloud Video Production Service enabling brands and agencies to get high quality online video content shot and produced anywhere in the world. 90 Seconds makes video production fast, affordable, and all managed seamlessly \n",
      "\n",
      "Cleaned Company Profile:\n",
      " seconds worlds cloud video production service seconds worlds cloud video production service enabling brands agencies get high quality online video content shot produced anywhere world seconds makes video production fast affordable managed seamlessly cloud purchase publish http url fbe afac cd c f b \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Task 1:\n",
    "\n",
    "Write your own cleaning function that:\n",
    "Removes HTML, numbers, and punctuation\n",
    "Converts text to lowercase\n",
    "Removes stopwords\n",
    "Returns a cleaned version of the company_profile column\"\"\"\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download once if not already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Fake_Jobs_Postings.csv')\n",
    "\n",
    "# Define custom cleaning function for company_profile\n",
    "def clean_company_profile(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "\n",
    "    # 3. Remove numbers and punctuation\n",
    "    text = re.sub(r'[%s\\d]' % re.escape(string.punctuation), ' ', text)\n",
    "\n",
    "    # 4. Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # 5. Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply function\n",
    "df['clean_company_profile'] = df['company_profile'].apply(clean_company_profile)\n",
    "\n",
    "# Display before and after\n",
    "print(\"Original Company Profile:\\n\", df['company_profile'].iloc[1][:300])\n",
    "print(\"\\nCleaned Company Profile:\\n\", df['clean_company_profile'].iloc[1][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4065985-dffe-4922-a2e5-c3858edd0ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'clean_description'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'clean_description'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Count before and after cleaning\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(word_count)\n\u001b[1;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(word_count)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate average word counts\u001b[39;00m\n\u001b[0;32m     15\u001b[0m avg_before \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'clean_description'"
     ]
    }
   ],
   "source": [
    "\"\"\"Task 2:\n",
    "Count the average number of words before and after cleaning for job descriptions.\n",
    "Discuss: Did the cleaning remove too much or just enough?\"\"\"\n",
    "# Define helper function to count words\n",
    "def word_count(text):\n",
    "    if pd.isnull(text):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "# Count before and after cleaning\n",
    "df['original_word_count'] = df['description'].apply(word_count)\n",
    "df['cleaned_word_count'] = df['clean_description'].apply(word_count)\n",
    "\n",
    "# Calculate average word counts\n",
    "avg_before = df['original_word_count'].mean()\n",
    "avg_after = df['cleaned_word_count'].mean()\n",
    "\n",
    "print(f\"\\nAverage number of words before cleaning: {avg_before:.2f}\")\n",
    "print(f\"Average number of words after cleaning: {avg_after:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd5817-f483-44ba-a200-44adbb534983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 4: Feature Extraction using BoW and TF-IDF\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    " \n",
    "# Load preprocessed dataset (from Day 3)\n",
    "\n",
    "df = pd.read_csv('Fake_Jobs_Postings.csv')\n",
    " \n",
    "# Assume we already created a 'clean_description' column\n",
    "\n",
    "texts = df['clean_description'].fillna('').tolist()\n",
    " \n",
    "# 1️⃣ Bag-of-Words\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_features=2000)  # limit to top 2000 words\n",
    "\n",
    "X_bow = bow_vectorizer.fit_transform(texts)\n",
    " \n",
    "print(\"BoW shape:\", X_bow.shape)\n",
    "\n",
    "print(\"Sample feature names (BoW):\", bow_vectorizer.get_feature_names_out()[:10])\n",
    " \n",
    "# 2️⃣ TF-IDF\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000)\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    " \n",
    "print(\"\\nTF-IDF shape:\", X_tfidf.shape)\n",
    "\n",
    "print(\"Sample feature names (TF-IDF):\", tfidf_vectorizer.get_feature_names_out()[:10])\n",
    " \n",
    "# 3️⃣ Compare sparsity and values\n",
    "\n",
    "print(\"\\nExample BoW vector (first row):\")\n",
    "\n",
    "print(X_bow[0].toarray())\n",
    " \n",
    "print(\"\\nExample TF-IDF vector (first row):\")\n",
    "\n",
    "print(X_tfidf[0].toarray())\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be8c72-d64d-4ef9-aeb2-92b901f88bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# 1. Drop missing values from company_profile\n",
    "df['company_profile'] = df['company_profile'].fillna('')\n",
    "\n",
    "# 2. Initialize Vectorizers\n",
    "bow_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# 3. Fit and transform the text\n",
    "bow_features = bow_vectorizer.fit_transform(df['company_profile'])\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['company_profile'])\n",
    "\n",
    "# 4. Compare shapes\n",
    "print(\"BoW shape:\", bow_features.shape)\n",
    "print(\"TF-IDF shape:\", tfidf_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d828b-1650-4e56-815d-4ee85ff115c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Fill missing values\n",
    "df['description'] = df['description'].fillna('')\n",
    "\n",
    "# 2. Create Bag of Words\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "bow_matrix = vectorizer.fit_transform(df['description'])\n",
    "\n",
    "# 3. Sum up word counts\n",
    "word_counts = bow_matrix.toarray().sum(axis=0)\n",
    "\n",
    "# 4. Create a DataFrame of words and their counts\n",
    "bow_df = pd.DataFrame({\n",
    "    'Word': vectorizer.get_feature_names_out(),\n",
    "    'Count': word_counts\n",
    "})\n",
    "\n",
    "# 5. Sort and display top 20\n",
    "top20_words = bow_df.sort_values(by='Count', ascending=False).head(20)\n",
    "print(top20_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4232d71b-2b55-4e6b-ac24-92ab022bad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9658836689038032\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3403\n",
      "           1       0.98      0.30      0.46       173\n",
      "\n",
      "    accuracy                           0.97      3576\n",
      "   macro avg       0.97      0.65      0.72      3576\n",
      "weighted avg       0.97      0.97      0.96      3576\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3402    1]\n",
      " [ 121   52]]\n",
      "\n",
      "Sample Predictions: [0 0]\n"
     ]
    }
   ],
   "source": [
    "# Day 5: Logistic Regression Model for Fake Job Detection\n",
    " \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    " \n",
    "# Load dataset (preprocessed with clean_description)\n",
    "df = pd.read_csv('Fake_Jobs_Postings.csv')\n",
    "df = df.dropna(subset=['description'])\n",
    "\n",
    " \n",
    "# 1 Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['description'])\n",
    "y = df['fraudulent']\n",
    " \n",
    "# 2 Split data into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    " \n",
    "# 3 Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# 4 Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "# 5 Evaluate performance\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    " \n",
    "# 6 Check example predictions\n",
    "test_samples = [\n",
    "    \"Work from home! Limited vacancies. Apply now.\",\n",
    "    \"We are hiring a data scientist for our Bangalore office.\"\n",
    "]\n",
    "sample_features = vectorizer.transform(test_samples)\n",
    "print(\"\\nSample Predictions:\", model.predict(sample_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
